{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30bd0c66",
   "metadata": {},
   "source": [
    "# Librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da0d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import holidays\n",
    "import calendar\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef78de5",
   "metadata": {},
   "source": [
    "# Lectura de datos:\n",
    "Se carga el dataset original y modificado para comparar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c5280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_bike_sharing_df = pd.read_csv('../data/raw/bike_sharing_original.csv')\n",
    "bike_sharing_df = pd.read_csv('../data/raw/bike_sharing_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43decb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros objetivo a eliminar 347\n",
      "Columnas objetivo a eliminar 1\n"
     ]
    }
   ],
   "source": [
    "target_rows_to_drop = bike_sharing_df.shape[0] - original_bike_sharing_df.shape[0]\n",
    "target_cols_to_drop = bike_sharing_df.shape[1] - original_bike_sharing_df.shape[1]\n",
    "\n",
    "print(f'Registros objetivo a eliminar {target_rows_to_drop}')\n",
    "print(f'Columnas objetivo a eliminar {target_cols_to_drop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca72c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_values(df):\n",
    "        column_types_map = {\n",
    "            'instant': 'int',\n",
    "            'season': 'int',\n",
    "            'yr': 'int',\n",
    "            'mnth': 'int',\n",
    "            'hr': 'int',\n",
    "            'holiday': 'int',\n",
    "            'weekday': 'int',\n",
    "            'workingday': 'int',\n",
    "            'weathersit': 'int',\n",
    "            'temp': 'float',\n",
    "            'atemp': 'float',\n",
    "            'hum': 'float',\n",
    "            'windspeed': 'float',\n",
    "            'casual': 'int',\n",
    "            'registered': 'int',\n",
    "            'cnt': 'int',\n",
    "            'mixed_type_col': 'int'\n",
    "        }\n",
    "\n",
    "        cast_map = {\n",
    "            'int': lambda df, col: pd.to_numeric(df[col], errors='coerce').astype('Int64'),\n",
    "            'float': lambda df, col: pd.to_numeric(df[col], errors='coerce').astype('float64')\n",
    "        }\n",
    "        \n",
    "        for col_name, target_dtype in column_types_map.items():\n",
    "            if col_name in df.columns:\n",
    "                cast_map.get(target_dtype.lower())\n",
    "\n",
    "                cast_action = cast_map.get(target_dtype.lower())\n",
    "\n",
    "                if cast_action:\n",
    "                    df[col_name] = cast_action(df, col_name)\n",
    "\n",
    "cast_values(bike_sharing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726a588e-c637-49f9-9b94-2f0e7054e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_cols(df):\n",
    "    cat_cols = df.select_dtypes(include = 'object').columns.tolist()\n",
    "\n",
    "    return cat_cols\n",
    "\n",
    "def get_num_cols(df):\n",
    "    num_cols = df.select_dtypes(exclude = 'object').columns.tolist()\n",
    "\n",
    "    return num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4edfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = get_cat_cols(bike_sharing_df)\n",
    "num_cols = get_num_cols(bike_sharing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c5515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df, cols):\n",
    "    df.drop(columns = cols, inplace=True)\n",
    "    print(f'Columna (s) {cols} eliminada (s) del dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8c8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_to_drop(baseline_df, modified_df):\n",
    "    original_cols = set(baseline_df.columns)\n",
    "    modified_cols = set(modified_df.columns)\n",
    "\n",
    "    cols_to_drop = []\n",
    "    diff_cols = modified_cols - original_cols\n",
    "\n",
    "    if len(diff_cols) == target_cols_to_drop:\n",
    "        cols_to_drop = diff_cols.pop()\n",
    "        print(f'Columna (s) a eliminar: {cols_to_drop}')\n",
    "\n",
    "    return cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2cdf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna (s) a eliminar: mixed_type_col\n",
      "Columna (s) mixed_type_col eliminada (s) del dataframe.\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = get_cols_to_drop(original_bike_sharing_df, bike_sharing_df)\n",
    "drop_cols(bike_sharing_df, cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df4ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = get_cat_cols(bike_sharing_df)\n",
    "num_cols = get_num_cols(bike_sharing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa9bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_values(df):\n",
    "        column_types_map = {\n",
    "            'instant': 'int',\n",
    "            'season': 'int',\n",
    "            'yr': 'int',\n",
    "            'mnth': 'int',\n",
    "            'hr': 'int',\n",
    "            'holiday': 'int',\n",
    "            'weekday': 'int',\n",
    "            'workingday': 'int',\n",
    "            'weathersit': 'int',\n",
    "            'temp': 'float',\n",
    "            'atemp': 'float',\n",
    "            'hum': 'float',\n",
    "            'windspeed': 'float',\n",
    "            'casual': 'int',\n",
    "            'registered': 'int',\n",
    "            'cnt': 'int',\n",
    "            'mixed_type_col': 'int'\n",
    "        }\n",
    "\n",
    "        cast_map = {\n",
    "            'int': lambda df, col: pd.to_numeric(df[col], errors='coerce').astype('Int64'),\n",
    "            'float': lambda df, col: pd.to_numeric(df[col], errors='coerce').astype('float64')\n",
    "        }\n",
    "        \n",
    "        for col_name, target_dtype in column_types_map.items():\n",
    "            if col_name in df.columns:\n",
    "                cast_map.get(target_dtype.lower())\n",
    "\n",
    "                cast_action = cast_map.get(target_dtype.lower())\n",
    "\n",
    "                if cast_action:\n",
    "                    df[col_name] = cast_action(df, col_name)\n",
    "\n",
    "cast_values(bike_sharing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29747539",
   "metadata": {},
   "source": [
    "# Limpieza de datos:\n",
    "- Manejo de valores faltantes en todas las variables\n",
    "- Manejo de valores atípicos en todas las variables\n",
    "- Estandarización de formato de fechas\n",
    "- Estandarización de parámetros (ej: formato 24 hrs para variable 'hr')\n",
    "- Manejo de operaciones aritméticas correctas ('casual' + 'registered' = 'cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba1d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 35452\n"
     ]
    }
   ],
   "source": [
    "## DATEDAY -> formato de fecha\n",
    "##\n",
    "def convert_date_format(df, date_col):\n",
    "    count = 0\n",
    "\n",
    "    df[date_col] = df[date_col].astype(str).str.strip()\n",
    "    initial_series = df[date_col].copy()\n",
    "\n",
    "    # Formato 1: YYYY-MM-DD\n",
    "    df[date_col] = pd.to_datetime(initial_series, format='%Y-%m-%d', errors='coerce')\n",
    "    \n",
    "    # Formato 2: MM/DD/YYYY (US)\n",
    "    mask_nan_us = df[date_col].isna()\n",
    "    \n",
    "    df.loc[mask_nan_us, date_col] = pd.to_datetime(\n",
    "        initial_series[mask_nan_us], \n",
    "        format='%m/%d/%Y', \n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    count += (~df[date_col].isna() | mask_nan_us).sum()\n",
    "\n",
    "    # Formato 3: DD/MM/YYYY (EU)\n",
    "    mask_nan_eu = df[date_col].isna()\n",
    "\n",
    "    df.loc[mask_nan_eu, date_col] = pd.to_datetime(\n",
    "        initial_series[mask_nan_eu], \n",
    "        format='%d/%m/%Y', \n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    count += (~df[date_col].isna() | mask_nan_eu).sum()\n",
    "\n",
    "    print(f'Datos manipulados: {count}')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = convert_date_format(bike_sharing_df, 'dteday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b875d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/m1wqqf692qndl4tszyqhty640000gn/T/ipykernel_47822/546339897.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[hour_col].fillna(-1.0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## HOUR\n",
    "##\n",
    "def clean_hour(df, hour_col, date_col):\n",
    "    CUTOFF_DATE = pd.to_datetime('2012-12-31')\n",
    "    CUTOFF_HR = 23.0 \n",
    "\n",
    "    count = 0\n",
    "\n",
    "    df[hour_col] = pd.to_numeric(df[hour_col], errors='coerce') # cast string a numérica para convertir valores corruptos a NaN\n",
    "    df[hour_col].fillna(-1.0, inplace=True)\n",
    "    df[hour_col] = df[hour_col].astype(float)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        \n",
    "        current_date = df.loc[i, date_col]\n",
    "        current_hr = df.loc[i, hour_col]\n",
    "        \n",
    "        prev_date = df.loc[i - 1, date_col]\n",
    "        prev_hr = df.loc[i - 1, hour_col]\n",
    "        \n",
    "        if prev_date == CUTOFF_DATE and prev_hr == CUTOFF_HR: # poka-yoke en la última hora del último día de 2012\n",
    "            break\n",
    "            \n",
    "        expected_hr = (prev_hr + 1) % 24 # formato 24 horas\n",
    "        \n",
    "        out_of_range_flag = (current_hr < 0) or (current_hr > 23)\n",
    "        \n",
    "        if out_of_range_flag:\n",
    "            # Caso 1: si el valor es 1) corrupto o 2) fuera del rango de 24 hr, imputamos el valor secuencial esperado\n",
    "            df.loc[i, hour_col] = expected_hr\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if expected_hr == 0:\n",
    "                if pd.notna(prev_date):\n",
    "                    df.loc[i, date_col] = prev_date + pd.Timedelta(days=1)\n",
    "                                    \n",
    "        elif current_hr != expected_hr:\n",
    "            # Caso 2: si es un salto en la secuencia numérica (ej. 1 -> 4) y NO es un cambio de día, no se realiza imputación\n",
    "            pass\n",
    "\n",
    "        df[hour_col] = df[hour_col].astype(int)\n",
    "\n",
    "        mask_final_outlier = (df[hour_col] < 0) | (df[hour_col] > 23)\n",
    "\n",
    "        if mask_final_outlier.sum() > 0:\n",
    "            indices_to_fix = df[mask_final_outlier].index\n",
    "            \n",
    "            for idx in indices_to_fix:\n",
    "                if idx > 0:\n",
    "                    prev_hr_fixed = df.loc[idx - 1, hour_col]\n",
    "                    prev_date_fixed = df.loc[idx - 1, date_col]\n",
    "                    \n",
    "                    expected_hr_current = (prev_hr_fixed + 1) % 24\n",
    "                    \n",
    "                    df.loc[idx, hour_col] = expected_hr_current\n",
    "                    \n",
    "                    count += 1\n",
    "\n",
    "                    if expected_hr_current == 0: # corregir dteday si hay salto de día\n",
    "                        if pd.notna(prev_date_fixed):\n",
    "                            df.loc[idx, date_col] = prev_date_fixed + pd.Timedelta(days=1)\n",
    "                else:\n",
    "                   df.loc[idx, hour_col] = 0.0\n",
    "                    \n",
    "        print(f'Datos manipulados: {count}')\n",
    "\n",
    "        df[hour_col] = df[hour_col].astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "bike_sharing_df = clean_hour(bike_sharing_df, 'hr', 'dteday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b013caf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 191\n"
     ]
    }
   ],
   "source": [
    "## DATE DAY\n",
    "#\n",
    "def impute_date(df, date_col, hour_col):\n",
    "    count = 0\n",
    "\n",
    "    mask_to_impute = df[date_col].isna() & \\\n",
    "                     df[hour_col].notna()\n",
    "\n",
    "    indixes_to_impute = df[mask_to_impute].index\n",
    "    \n",
    "    for idx in indixes_to_impute:\n",
    "        if idx > 0:\n",
    "            \n",
    "            current_hr = df.loc[idx, hour_col]\n",
    "            prev_idx = idx - 1\n",
    "            prev_dteday = df.loc[prev_idx, date_col]\n",
    "            prev_hr = df.loc[prev_idx, hour_col]\n",
    "            \n",
    "            if pd.isna(prev_dteday):\n",
    "                continue # si no hay fecha anterior, se omite\n",
    "            \n",
    "            sequential_jump_flag = (current_hr == (prev_hr + 1)) or (prev_hr == 23 and current_hr == 0)\n",
    "            \n",
    "            if sequential_jump_flag:\n",
    "                \n",
    "                if current_hr == 0:\n",
    "                    new_date = prev_dteday + pd.Timedelta(days=1)\n",
    "                \n",
    "                else:\n",
    "                    new_date = prev_dteday\n",
    "                \n",
    "                df.loc[idx, date_col] = new_date\n",
    "                count += 1\n",
    "\n",
    "    print(f'Datos manipulados: {count}')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = impute_date(bike_sharing_df, 'dteday', 'hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9054dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/m1wqqf692qndl4tszyqhty640000gn/T/ipykernel_47822/1651103133.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[year_col].fillna(df[date_col].dt.year.map(YEAR_MAPPING), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## YEAR\n",
    "##\n",
    "def clean_year(df, year_col, date_col):\n",
    "    YEAR_MAPPING = {2011: 0.0, 2012: 1.0}\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    count_before_fillna = df[year_col].isna().sum()\n",
    "    df[year_col].fillna(df[date_col].dt.year.map(YEAR_MAPPING), inplace=True)\n",
    "    count += count_before_fillna - df[year_col].isna().sum()\n",
    "\n",
    "    df[year_col] = pd.to_numeric(df[year_col], errors='coerce')\n",
    "\n",
    "    mask_corrupt_year = (df[year_col].isna()) | \\\n",
    "                    (~df[year_col].isin([0.0, 1.0])) # rango [0,1] para años (2011, 2012)\n",
    "    count += mask_corrupt_year.sum() \n",
    "\n",
    "    imputed_yr_values = df.loc[mask_corrupt_year, date_col].dt.year.map(YEAR_MAPPING)\n",
    "\n",
    "    df.loc[mask_corrupt_year, year_col] = imputed_yr_values\n",
    "\n",
    "    print(f'Datos manipulados: {count}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = clean_year(bike_sharing_df, 'yr', 'dteday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fd1676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/m1wqqf692qndl4tszyqhty640000gn/T/ipykernel_47822/1326134060.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[month_col].fillna(df[date_col].dt.month, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## MONTH\n",
    "##\n",
    "def clean_month(df, month_col, date_col):\n",
    "    count = 0\n",
    "\n",
    "    count_before_fillna = df[month_col].isna().sum() \n",
    "    df[month_col].fillna(df[date_col].dt.month, inplace=True)\n",
    "    count += count_before_fillna - df[month_col].isna().sum()\n",
    "    \n",
    "    df[month_col] = pd.to_numeric(df[month_col], errors='coerce')\n",
    "\n",
    "    mask_corrupt_month = (df[month_col].isna()) | \\\n",
    "                        (df[month_col] < 1) | \\\n",
    "                        (df[month_col] > 12) # rango [1-12] para meses\n",
    "    count += mask_corrupt_month.sum()\n",
    "\n",
    "    df.loc[mask_corrupt_month, month_col] = df.loc[mask_corrupt_month, date_col].dt.month.astype(float)\n",
    "\n",
    "    print(f'Datos manipulados: {count}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = clean_month(bike_sharing_df, 'mnth', 'dteday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b242a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/m1wqqf692qndl4tszyqhty640000gn/T/ipykernel_47822/1909220552.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[weekday_col].fillna(df[date_col].dt.weekday, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## WEEKDAY\n",
    "##\n",
    "def clean_weekday(df, weekday_col, date_col):\n",
    "    count = 0\n",
    "\n",
    "    count_before_fillna = df[weekday_col].isna().sum()\n",
    "    df[weekday_col].fillna(df[date_col].dt.weekday, inplace=True)\n",
    "    count += count_before_fillna - df[weekday_col].isna().sum()\n",
    "\n",
    "    df[weekday_col] = pd.to_numeric(df[weekday_col], errors='coerce')\n",
    "\n",
    "    mask_corrupt_weekday = (bike_sharing_df[weekday_col].isna()) | \\\n",
    "                        (bike_sharing_df[weekday_col] < 0) | \\\n",
    "                        (bike_sharing_df[weekday_col] > 6) # rango [0-6] para días de la semana\n",
    "    count += mask_corrupt_weekday.sum()\n",
    "\n",
    "    imputed_weekday_values = bike_sharing_df.loc[mask_corrupt_weekday, date_col].dt.weekday.astype(float)\n",
    "\n",
    "    bike_sharing_df.loc[mask_corrupt_weekday, weekday_col] = imputed_weekday_values\n",
    "\n",
    "    print(f'Datos manipulados: {count}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = clean_weekday(bike_sharing_df, 'weekday', 'dteday')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "132a0abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 345\n"
     ]
    }
   ],
   "source": [
    "## HOLIDAY\n",
    "#\n",
    "def clean_holiday(df, holiday_col, date_col):\n",
    "    count = 0\n",
    "\n",
    "    us_holidays = holidays.US(years=[2011, 2012])\n",
    "\n",
    "    def get_us_holiday(date):\n",
    "        if pd.isna(date):\n",
    "            return np.nan\n",
    "        \n",
    "        return 1.0 if date in us_holidays else 0.0\n",
    "\n",
    "\n",
    "    df[holiday_col] = pd.to_numeric(df[holiday_col], errors='coerce')\n",
    "\n",
    "    mask_corrupt_holiday = (df[holiday_col].isna()) | \\\n",
    "                        (~df[holiday_col].isin([0.0, 1.0]))\n",
    "    count += mask_corrupt_holiday.sum()\n",
    "\n",
    "    imputed_holiday_values = df.loc[mask_corrupt_holiday, date_col].apply(get_us_holiday)\n",
    "\n",
    "    df.loc[mask_corrupt_holiday, holiday_col] = imputed_holiday_values\n",
    "    df[holiday_col].astype(int)\n",
    "    \n",
    "    print(f'Datos manipulados: {count}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = clean_holiday(bike_sharing_df, 'holiday', 'dteday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e04e3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 388\n"
     ]
    }
   ],
   "source": [
    "## WORKING DAY\n",
    "#\n",
    "def clean_workday(df, workday_col, weekday_col, holiday_col):\n",
    "    count = 0\n",
    "    \n",
    "    df[workday_col] = pd.to_numeric(df[workday_col], errors='coerce')\n",
    "\n",
    "    mask_corrupt_workingday = (df[workday_col].isna()) | \\\n",
    "                            (~df[workday_col].isin([0.0, 1.0]))\n",
    "    count += mask_corrupt_workingday.sum()\n",
    "\n",
    "    imputed_workingday_values = df.loc[mask_corrupt_workingday, weekday_col].apply(\n",
    "        lambda x: 0.0 if x in [0.0, 6.0] else 1.0\n",
    "    ) # si 'weekday' está en [0, 6], 'workingday' debe ser 0, sino debe ser 1\n",
    "\n",
    "    df.loc[mask_corrupt_workingday, workday_col] = imputed_workingday_values\n",
    "    count += (df.loc[df[holiday_col] == 1.0, workday_col] != 0.0).sum()\n",
    "\n",
    "    df.loc[df[holiday_col] == 1.0, workday_col] = 0.0 # si es día festivo (holiday=1), NO puede ser día laboral (workingday=0)\n",
    "\n",
    "    print(f'Datos manipulados: {count}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = clean_workday(bike_sharing_df, 'workingday', 'weekday', 'holiday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9203ee1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 432\n"
     ]
    }
   ],
   "source": [
    "## SEASON\n",
    "#\n",
    "def map_season(current_date):\n",
    "    \n",
    "    if pd.isna(current_date):\n",
    "        return np.nan\n",
    "    \n",
    "    month_day = (current_date.month, current_date.day)\n",
    "\n",
    "    # 1.0 == invierno: 21-Dic al 20-Mar\n",
    "    if (month_day >= (12, 21)) or (month_day <= (3, 20)):\n",
    "        return 1.0 \n",
    "    \n",
    "    # 2.0 == primavera: 21-Mar al 20-Jun\n",
    "    elif (month_day >= (3, 21)) and (month_day <= (6, 20)):\n",
    "        return 2.0\n",
    "        \n",
    "    # 3.0 == verano: 21-Jun al 22-Sep\n",
    "    elif (month_day >= (6, 21)) and (month_day <= (9, 22)):\n",
    "        return 3.0\n",
    "        \n",
    "    # 4.0 == otoño): 23-Sep al 20-Dic\n",
    "    elif (month_day >= (9, 23)) and (month_day <= (12, 20)):\n",
    "        return 4.0\n",
    "        \n",
    "    return np.nan\n",
    "\n",
    "def clean_season(df, season_col, date_col):\n",
    "    count = 0\n",
    "\n",
    "    df[season_col] = pd.to_numeric(df[season_col], errors='coerce')\n",
    "\n",
    "    mask_corrupt_season = (df[season_col].isna()) | \\\n",
    "                        (df[season_col] < 1.0) | \\\n",
    "                        (df[season_col] > 4.0) | \\\n",
    "                        (df[season_col] % 1 != 0)\n",
    "    count += mask_corrupt_season.sum()\n",
    "\n",
    "    imputed_season_values = df.loc[mask_corrupt_season, date_col].apply(map_season)\n",
    "\n",
    "    df.loc[mask_corrupt_season, season_col] = imputed_season_values\n",
    "\n",
    "    print(f'Datos manipulados: {count}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = clean_season(bike_sharing_df, 'season', 'dteday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b58bba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 260\n"
     ]
    }
   ],
   "source": [
    "## INSTANT\n",
    "#\n",
    "def impute_instant(df, instant_col, date_col, hour_col):\n",
    "    count = 0\n",
    "\n",
    "    mask_instant_nan = df[instant_col].isna()\n",
    "    indexes_to_impute = df[mask_instant_nan].index\n",
    "    \n",
    "    for idx in indexes_to_impute:\n",
    "        \n",
    "        if idx > 0 and idx < len(df) - 1:\n",
    "            \n",
    "            prev_idx = idx - 1\n",
    "            prev_instant = df.loc[prev_idx, instant_col]\n",
    "            prev_date = df.loc[prev_idx, date_col]\n",
    "            prev_hr = df.loc[prev_idx, hour_col]\n",
    "            \n",
    "            next_idx = idx + 1\n",
    "            next_instant = df.loc[next_idx, instant_col]\n",
    "            next_date = df.loc[next_idx, date_col]\n",
    "            next_hr = df.loc[next_idx, hour_col]\n",
    "            \n",
    "            current_date = df.loc[idx, date_col]\n",
    "            current_hr = df.loc[idx, hour_col]\n",
    "            \n",
    "            if pd.isna(prev_instant) or pd.isna(next_instant):\n",
    "                continue\n",
    "                \n",
    "            if next_instant - prev_instant != 2:\n",
    "                continue\n",
    "                \n",
    "            expected_hr_current = (prev_hr + 1) % 24\n",
    "            sequential_hr_flag = current_hr == expected_hr_current\n",
    "            \n",
    "            if expected_hr_current == 0:\n",
    "                expected_date = prev_date + pd.Timedelta(days=1)\n",
    "                sequential_date_flag = current_date == expected_date\n",
    "            else:\n",
    "                sequential_date_flag = current_date == prev_date\n",
    "\n",
    "            if sequential_hr_flag and sequential_date_flag:                \n",
    "                imputed_value = prev_instant + 1.0\n",
    "                df.loc[idx, instant_col] = imputed_value\n",
    "                count += 1\n",
    "                \n",
    "    print(f'Datos manipulados: {count}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_max_records():\n",
    "    HOURS_PER_DAY = 24\n",
    "    \n",
    "    days_in_2011 = 366 if calendar.isleap(2011) else 365\n",
    "    days_in_2012 = 366 if calendar.isleap(2012) else 365    \n",
    "\n",
    "    total = (days_in_2011 + days_in_2012) * HOURS_PER_DAY\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "bike_sharing_df = impute_instant(bike_sharing_df, 'instant', 'dteday', 'hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a4959d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros eliminados: 327\n"
     ]
    }
   ],
   "source": [
    "def crosscheck_duplicates(df): # eliminar registros duplicados con menor cantidad de valores faltantes\n",
    "    key_columns = ['instant', 'dteday', 'hr']\n",
    "    rows_before_cleanup = df.shape[0]\n",
    "\n",
    "    # corección: hay registros con un valor en 'instant' duplicados (1 registro con valores en dteday y otro con valores faltantes)\n",
    "    df_valid_dates = df.dropna(subset=['dteday']).copy()\n",
    "\n",
    "    df_valid_dates.drop_duplicates(subset=['instant'], keep='first', inplace=True)\n",
    "\n",
    "    instant_to_dteday_map = df_valid_dates.set_index('instant')['dteday']\n",
    "\n",
    "    mask_dteday_nan = df['dteday'].isna()\n",
    "    df.loc[mask_dteday_nan, 'dteday'] = df.loc[mask_dteday_nan, 'instant'].map(instant_to_dteday_map)\n",
    "\n",
    "    df['tmp_nan_count'] = df.isnull().sum(axis=1)\n",
    "\n",
    "    df.sort_values(\n",
    "        by=key_columns + ['tmp_nan_count'],\n",
    "        ascending=[True, True, True, True],\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    df.drop_duplicates(subset=key_columns, keep='first', inplace=True)\n",
    "\n",
    "    df.drop(columns=['tmp_nan_count'], inplace=True, errors='ignore')\n",
    "\n",
    "    rows_after_cleanup = df.shape[0]\n",
    "    total_dropped_rows = rows_before_cleanup - rows_after_cleanup\n",
    "\n",
    "    print(f'Registros eliminados: {total_dropped_rows}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = crosscheck_duplicates(bike_sharing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d5e0218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados: 3542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/m1wqqf692qndl4tszyqhty640000gn/T/ipykernel_47822/4228118858.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['weathersit'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/dt/m1wqqf692qndl4tszyqhty640000gn/T/ipykernel_47822/4228118858.py:20: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['weathersit'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/dt/m1wqqf692qndl4tszyqhty640000gn/T/ipykernel_47822/4228118858.py:21: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['weathersit'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def impute_weather_details(df):\n",
    "    count = 0\n",
    "    \n",
    "    weather_cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "\n",
    "    mask_hum_outlier = (df['hum'] < 0) | (df['hum'] > 100)\n",
    "    df.loc[mask_hum_outlier, 'hum'] = np.nan\n",
    "    \n",
    "    mask_windspeed_outlier = (df['windspeed'] == 0) | (df['windspeed'] > 60)\n",
    "    df.loc[mask_windspeed_outlier, 'windspeed'] = np.nan\n",
    "\n",
    "    nan_count_knn = df[weather_cols].isna().sum().sum()\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    df[weather_cols] = imputer.fit_transform(df[weather_cols])\n",
    "\n",
    "    nan_count_weathersit = df['weathersit'].isna().sum() \n",
    "\n",
    "    df['weathersit'].fillna(method='ffill', inplace=True)\n",
    "    df['weathersit'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "    count = nan_count_knn + nan_count_weathersit\n",
    "\n",
    "    df['weathersit'] = df['weathersit'].astype(int)\n",
    "\n",
    "    print(f'Datos manipulados: {count}')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = impute_weather_details(bike_sharing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01f6ac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados (celdas): 1198\n",
      "Registros eliminados: 24\n"
     ]
    }
   ],
   "source": [
    "def impute_bikes_total_count(df):\n",
    "    count = 0\n",
    "\n",
    "    count_cols = ['cnt', 'registered', 'casual']\n",
    "    rows_initial = df.shape[0]\n",
    "\n",
    "    mask_not_nan = df[count_cols].notna().all(axis=1)\n",
    "\n",
    "    # registered > cnt\n",
    "    mask_reg_too_high = mask_not_nan & (df['registered'] > df['cnt'])\n",
    "    count += mask_reg_too_high.sum()\n",
    "    df.loc[mask_reg_too_high, 'registered'] = df['cnt'] - df['casual']\n",
    "    \n",
    "    # casual > cnt\n",
    "    mask_casual_too_high = mask_not_nan & (df['casual'] > df['cnt'])\n",
    "    count += mask_casual_too_high.sum()\n",
    "    df.loc[mask_casual_too_high, 'casual'] = df['cnt'] - df['registered']\n",
    "    \n",
    "    # correción de 'cnt' donde la suma no cuadra (ej: cnt=13, reg=10, cas=0),\n",
    "    mask_incorrect_sum = df[count_cols].notna().all(axis=1) & (df['cnt'] != (df['registered'] + df['casual']))\n",
    "    count += mask_incorrect_sum.sum()\n",
    "    df.loc[mask_incorrect_sum, 'cnt'] = df['registered'] + df['casual']\n",
    "    \n",
    "    # cnt = registered + casual\n",
    "    mask_impute_cnt = df['cnt'].isna() & df['registered'].notna() & df['casual'].notna()\n",
    "    count += mask_impute_cnt.sum()\n",
    "    df.loc[mask_impute_cnt, 'cnt'] = df['registered'] + df['casual']\n",
    "    \n",
    "    # registered = cnt - casual\n",
    "    mask_impute_registered = df['registered'].isna() & df['cnt'].notna() & df['casual'].notna()\n",
    "    count += mask_impute_registered.sum()\n",
    "    df.loc[mask_impute_registered, 'registered'] = df['cnt'] - df['casual']\n",
    "\n",
    "    # casual = cnt - registered\n",
    "    mask_impute_casual = df['casual'].isna() & df['cnt'].notna() & df['registered'].notna()\n",
    "    count += mask_impute_casual.sum()\n",
    "    df.loc[mask_impute_casual, 'casual'] = df['cnt'] - df['registered']\n",
    "\n",
    "    # ajustar valores negativos a NaN (resultado de restas o corrupción)\n",
    "    mask_negatives = (df['registered'] < 0) | (df['casual'] < 0) | (df['cnt'] < 0)\n",
    "    count += mask_negatives.sum()\n",
    "    df.loc[mask_negatives, count_cols] = np.nan\n",
    "    \n",
    "    # eliminar filas que aún tienen NaN (2+ valores NaN, o se volvieron negativos)\n",
    "    df.dropna(subset=count_cols, inplace=True)\n",
    "    rows_dropped_total = rows_initial - df.shape[0]\n",
    "\n",
    "    print(f'Datos manipulados (celdas): {count}')\n",
    "    print(f'Registros eliminados: {rows_dropped_total}')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = impute_bikes_total_count(bike_sharing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "413b5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos manipulados (celdas): 17375\n"
     ]
    }
   ],
   "source": [
    "def rebuild_instant(df, instant_col):\n",
    "    count = 0\n",
    "\n",
    "    sort_key = ['dteday', 'hr']\n",
    "    df.sort_values(by=sort_key, inplace=True, ignore_index=True)\n",
    "    \n",
    "    count = df.shape[0] \n",
    "\n",
    "    new_instant = df.index + 1\n",
    "    \n",
    "    df[instant_col] = new_instant.astype(int)\n",
    "    \n",
    "    max_instant = df[instant_col].max()\n",
    "\n",
    "    print(f'Datos manipulados (celdas): {count}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bike_sharing_df = rebuild_instant(bike_sharing_df, 'instant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df772f1c",
   "metadata": {},
   "source": [
    "# Verificación de datos post-limpieza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba3cb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NaN_values(df):\n",
    "    print(f'Valores NaN:\\n')\n",
    "    print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dbe3613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores NaN:\n",
      "\n",
      "instant       0\n",
      "dteday        0\n",
      "season        0\n",
      "yr            0\n",
      "mnth          0\n",
      "hr            0\n",
      "holiday       0\n",
      "weekday       0\n",
      "workingday    0\n",
      "weathersit    0\n",
      "temp          0\n",
      "atemp         0\n",
      "hum           0\n",
      "windspeed     0\n",
      "casual        0\n",
      "registered    0\n",
      "cnt           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "get_NaN_values(bike_sharing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8796c6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17375, 17)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e04eea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_summary(df, num_cols):\n",
    "    summary_data = []\n",
    "    \n",
    "    for col in num_cols:\n",
    "        skew = df[col].skew()\n",
    "        \n",
    "        if skew > 0.5:\n",
    "            skew_interpret = 'Sesgo Derecho (Positivo)'\n",
    "        elif skew < -0.5:\n",
    "            skew_interpret = 'Sesgo Izquierdo (Negativo)'\n",
    "        else:\n",
    "            skew_interpret = 'Simétrico/Ligero'\n",
    "        \n",
    "        \n",
    "        kurtosis = df[col].kurtosis()\n",
    "\n",
    "        if kurtosis > 0.5:\n",
    "            kurtosis_interpret = 'Leptocúrtica (Colas Pesadas)'\n",
    "        elif kurtosis < -0.5:\n",
    "            kurtosis_interpret = 'Platicúrtica (Colas Ligeras)'\n",
    "        else:\n",
    "            kurtosis_interpret = 'Mesocúrtica (Normal)'\n",
    "\n",
    "        summary_data.append({\n",
    "            'Variable': col,\n",
    "            'Skewness': skew,\n",
    "            'Kurtosis': kurtosis,\n",
    "            'Tipo de Sesgo': skew_interpret,\n",
    "            'Forma de la Distribucion': kurtosis_interpret\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df[['Skewness', 'Kurtosis']] = summary_df[['Skewness', 'Kurtosis']].round(2)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54bf8b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Tipo de Sesgo</th>\n",
       "      <th>Forma de la Distribucion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>instant</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>Simétrico/Ligero</td>\n",
       "      <td>Platicúrtica (Colas Ligeras)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>season</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>Simétrico/Ligero</td>\n",
       "      <td>Platicúrtica (Colas Ligeras)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yr</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>Simétrico/Ligero</td>\n",
       "      <td>Platicúrtica (Colas Ligeras)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnth</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>Simétrico/Ligero</td>\n",
       "      <td>Platicúrtica (Colas Ligeras)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hr</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>Simétrico/Ligero</td>\n",
       "      <td>Platicúrtica (Colas Ligeras)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>holiday</td>\n",
       "      <td>5.61</td>\n",
       "      <td>29.51</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weekday</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>Simétrico/Ligero</td>\n",
       "      <td>Platicúrtica (Colas Ligeras)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>workingday</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>Sesgo Izquierdo (Negativo)</td>\n",
       "      <td>Platicúrtica (Colas Ligeras)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weathersit</td>\n",
       "      <td>16.01</td>\n",
       "      <td>273.69</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>temp</td>\n",
       "      <td>17.01</td>\n",
       "      <td>305.81</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>atemp</td>\n",
       "      <td>16.16</td>\n",
       "      <td>278.23</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hum</td>\n",
       "      <td>18.60</td>\n",
       "      <td>378.88</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>windspeed</td>\n",
       "      <td>20.42</td>\n",
       "      <td>515.57</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>casual</td>\n",
       "      <td>112.04</td>\n",
       "      <td>13917.30</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>registered</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.87</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cnt</td>\n",
       "      <td>41.55</td>\n",
       "      <td>3649.89</td>\n",
       "      <td>Sesgo Derecho (Positivo)</td>\n",
       "      <td>Leptocúrtica (Colas Pesadas)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variable  Skewness  Kurtosis               Tipo de Sesgo  \\\n",
       "0      instant      0.00     -1.20            Simétrico/Ligero   \n",
       "1       season     -0.01     -1.33            Simétrico/Ligero   \n",
       "2           yr     -0.01     -2.00            Simétrico/Ligero   \n",
       "3         mnth     -0.01     -1.20            Simétrico/Ligero   \n",
       "4           hr     -0.01     -1.20            Simétrico/Ligero   \n",
       "5      holiday      5.61     29.51    Sesgo Derecho (Positivo)   \n",
       "6      weekday     -0.00     -1.26            Simétrico/Ligero   \n",
       "7   workingday     -0.78     -1.38  Sesgo Izquierdo (Negativo)   \n",
       "8   weathersit     16.01    273.69    Sesgo Derecho (Positivo)   \n",
       "9         temp     17.01    305.81    Sesgo Derecho (Positivo)   \n",
       "10       atemp     16.16    278.23    Sesgo Derecho (Positivo)   \n",
       "11         hum     18.60    378.88    Sesgo Derecho (Positivo)   \n",
       "12   windspeed     20.42    515.57    Sesgo Derecho (Positivo)   \n",
       "13      casual    112.04  13917.30    Sesgo Derecho (Positivo)   \n",
       "14  registered      1.57      2.87    Sesgo Derecho (Positivo)   \n",
       "15         cnt     41.55   3649.89    Sesgo Derecho (Positivo)   \n",
       "\n",
       "        Forma de la Distribucion  \n",
       "0   Platicúrtica (Colas Ligeras)  \n",
       "1   Platicúrtica (Colas Ligeras)  \n",
       "2   Platicúrtica (Colas Ligeras)  \n",
       "3   Platicúrtica (Colas Ligeras)  \n",
       "4   Platicúrtica (Colas Ligeras)  \n",
       "5   Leptocúrtica (Colas Pesadas)  \n",
       "6   Platicúrtica (Colas Ligeras)  \n",
       "7   Platicúrtica (Colas Ligeras)  \n",
       "8   Leptocúrtica (Colas Pesadas)  \n",
       "9   Leptocúrtica (Colas Pesadas)  \n",
       "10  Leptocúrtica (Colas Pesadas)  \n",
       "11  Leptocúrtica (Colas Pesadas)  \n",
       "12  Leptocúrtica (Colas Pesadas)  \n",
       "13  Leptocúrtica (Colas Pesadas)  \n",
       "14  Leptocúrtica (Colas Pesadas)  \n",
       "15  Leptocúrtica (Colas Pesadas)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distribution_summary(bike_sharing_df, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa3b7c0",
   "metadata": {},
   "source": [
    "# Versionamiento de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7965d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_sharing_df.to_csv('../data/processed/bike_sharing_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
